# GLAT (Generative AI Literacy Assessment Test) - Final 20-Item Version

**Validated Assessment Tool**  
Cronbach's alpha = 0.80 | Omega total = 0.81

---

## Know & Understand

### Question 1
Which of the following best describes "Generative AI"?

A. AI that creates new content like text, images, or music by learning from existing data.  
B. An AI system designed to enhance the speed and accuracy of data retrieval in search engines.  
C. A form of artificial intelligence that focuses on translating languages in real-time.  
D. AI technology used primarily for managing and organizing large databases.

---

### Question 2
Which of the following statements best describes an LLM (Large Language Model)?

A. It generates text by analyzing and summarizing large volumes of web content.  
B. It generates text by predicting the next word based on the context of previous words.  
C. It generates text by translating input text into multiple languages simultaneously.  
D. It generates text by using pre-defined templates and filling in the blanks.

---

### Question 3
Which of the following tasks can Generative AI perform with a high degree of accuracy?

A. Predicting stock market trends  
B. Making ethical decisions in complex scenarios  
C. Diagnosing rare diseases  
D. Generating human-like text based on prompts

---

### Question 4
In the context of Generative AI, what is "zero-shot learning"?

A. Training a model without any data.  
B. The ability of a model to perform a task without any task-specific training.  
C. A method of reducing the model's training time to zero.  
D. A technique for generating synthetic training data.

---

### Question 5
Which of the following is a potential challenge when using prompt-based development for text generation?

A. The language model can only generate binary outputs.  
B. The need for extensive labelled data to train the model.  
C. Crafting a prompt that accurately captures the desired context and nuances.  
D. The requirement for complex feature engineering.

---

### Question 7
What does the term "token" refer to in the context of a large language model (LLM)?

A. A token is a unit of text, such as a word or a subword, that the model processes individually.  
B. A token is a unique identifier assigned to each user interacting with the language model.  
C. A token is a security measure used to authenticate API requests to the language model.  
D. A token is a reward given to users for contributing valuable data to train the language model.

---

### Question 8
Which of the following is NOT a requirement for an AI to be considered artificial general intelligence (AGI)?

A. The ability to learn and adapt to new tasks without human intervention.  
B. The capability to perform tasks across various domains with human-like proficiency.  
C. The ability to predict future events with perfect accuracy.  
D. The capacity to understand and generate natural language.

---

### Question 10
How does RAG (Retrieval-Augmented Generation) enhance the capabilities of an LLM?

A. By improving its grammar and syntax.  
B. By providing it with real-time and relevant data.  
C. By increasing its computational speed.  
D. By enabling it to understand multiple languages.

---

## Use & Apply

### Question 11
When using generative AI to create a marketing pitch, which of the following strategies is least likely to be effective?

A. Supplying the AI with information about the target audience  
B. Asking the AI to include unique selling points and benefits  
C. Requesting the AI to use persuasive language techniques  
D. Providing the AI with a list of competitors' products

---

### Question 12
After deploying a customer service chatbot, you notice that it frequently provides outdated information about company policies. What is the best course of action to address this issue?

A. Implement a feedback loop where users can flag outdated information for review.  
B. Schedule regular updates to the chatbot's training data to include the latest company policies.  
C. Set up a system where complex or policy-related queries are escalated to human agents for accurate responses.  
D. Conduct a comprehensive audit of the chatbot's performance metrics to identify areas for improvement.

---

### Question 13
Suppose you have a large dataset of emails and you want to build an application to answer questions based on this dataset. Which of the following scenarios best illustrates the advantage of using RAG over prompting (i.e., without RAG)?

A. You need to generate creative writing pieces based on the email content.  
B. You want to ensure the model can answer questions even if it has never seen similar questions before.  
C. You need to answer questions that require specific information from different parts of the email dataset.  
D. You want to reduce the size of the language model to save computational resources.

---

## Evaluate & Create

### Question 16
As a student using a Large Language Model (LLM) to gather information for an assignment, how should you approach the information it provides?

A. The LLM's answers are always more trustworthy than any information you will find on the internet, so you can use them without further verification.  
B. The LLM's answers are generally more trustworthy than internet sources, but you should still verify the information with other reliable sources.  
C. The LLM's answers are not necessarily more trustworthy than internet sources, and you should cross-check the information with other credible references.  
D. The LLM's answers are less trustworthy than internet sources because it relies on outdated information.

---

### Question 17
It is unlikely for an LLM to provide an accurate summary of the latest financial market trends in real-time. Is this statement true or false?

A. True, because the LLM's data may be outdated due to its knowledge cutoff.  
B. True, because the LLM is not good at handling numbers and structured data.  
C. False, because the LLM frequently updates its knowledge base.  
D. False, because the LLM is capable of synthesizing the latest market data automatically.

---

### Question 18
A generative AI tool has provided a summary of a research paper. The summary states, "The study found that increased screen time is directly correlated with decreased attention spans in children aged 8-12." What is your next step?

A. Accept the summary as accurate because AI tools are generally reliable.  
B. Ask the AI to provide more details about the study's methodology and results.  
C. Cross-check the summary with the original research paper.  
D. Use another AI tool to generate a summary for comparison and evaluate the consistency between both summaries.

---

### Question 19
While reviewing a video of a well-known public figure making controversial statements, which characteristic confirms the video was NOT generated by AI?

A. The public figure's voice sounds like themselves.  
B. The video has a professional and polished appearance.  
C. The video is high-quality with smooth transitions.  
D. None of the above.

---

## Ethics

### Question 21
When a generative AI system is used for screening job applications, what issue might arise concerning the quality and fairness of hiring decisions?

A. The AI system might overlook applicants' unique achievements and extracurricular activities.  
B. The AI system could misinterpret minor formatting differences in resumes.  
C. The AI system might not effectively handle applications submitted in various languages.  
D. The AI system could reinforce existing biases found in historical hiring data.

---

### Question 22
In a healthcare startup, an accurate AI model recommends treatments, but doctors don't trust it because they can't understand how the model arrived at its conclusions. What core issue does this scenario illustrate?

A. The AI model uses obsolete training data.  
B. The training dataset lacks sufficient diversity.  
C. The treatment guidelines input are incorrect.  
D. The AI model behaves as a black box.

---

### Question 23
What are the potential copyright implications for a journalist using an AI-generated image in a commercial article?

A. The journalist needs to check the licensing policy of the AI tool they used.  
B. The AI-generated image is automatically free to use without any restrictions.  
C. The journalist must pay a standard licensing fee to use the AI-generated image.  
D. The image cannot be used in any commercial context because it is AI-generated.

---

### Question 24
Should we impose restrictions on the outputs of generative AI technologies?

A. Yes, to reduce the computational resources required for operating these technologies.  
B. Yes, to prevent the dissemination of harmful or misleading content.  
C. No, as it would hinder technological innovation and creativity.  
D. No, because users should have the freedom to access all generated content.

---

### Question 25
Sending personal information to cloud-based generative AI tools has little privacy concerns.

A. True, as this information is encrypted using sophisticated algorithms during the transmission process.  
B. True, as generative AI tools are black-box systems and cannot output personal information even if it is used for model training.  
C. False, as generative AI tools train on unencrypted data and can output private information based on their probabilistic nature.  
D. False, as advancements in quantum computing can easily decipher the encrypted data.

---

## Assessment Information

**Total Items:** 20 multiple-choice questions  
**Dimensions Assessed:**
- Know & Understand (8 items)
- Use & Apply (3 items)
- Evaluate & Create (4 items)
- Ethics (5 items)

**Psychometric Properties:**
- Cronbach's alpha: 0.80
- Omega total: 0.81
- Model: 2-parameter logistic (2PL) IRT model
- RMSEA: 0.031
- CFI: 0.970
- Test provides most reliable measurement for students with low to moderate GenAI literacy

**Citation:**
Jin, Y., Martinez-Maldonado, R., Gašević, D., & Yan, L. (2025). GLAT: The generative AI literacy assessment test. Computers and Education: Artificial Intelligence, 9, 100436.

**Note:** Item numbering retained from original 25-item version for reference consistency.
